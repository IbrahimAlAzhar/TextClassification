{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BiLSTM - CNN- attention 6 authors.ipynb","provenance":[{"file_id":"1gcUDJR5e82xihk1Pr1fYmxVK-3l8L2XR","timestamp":1603062392078}],"collapsed_sections":[],"authorship_tag":"ABX9TyP5fbO4m1+FowiBMpv+1E8J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2RQWx_OExi2T"},"source":["import os\n","import re\n","from tqdm import tqdm\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Dense, Dropout, LSTM, Embedding, Bidirectional\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import TensorBoard\n","from sklearn.model_selection import train_test_split\n","from keras.layers import Embedding\n","from  keras . utils  import  to_categorical\n","from keras.layers import Dense, Input, GlobalMaxPooling1D\n","from keras.layers import Conv1D,Conv2D, MaxPooling1D, Embedding, Flatten\n","from keras.models import Model\n","from keras.initializers import Constant\n","from keras.layers import Embedding\n","\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Y6KmqGbx-se","executionInfo":{"status":"ok","timestamp":1603063717519,"user_tz":-360,"elapsed":139417,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"5527c550-26d0-4d7c-ff54-848342585fa8","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mrh3q0CRx-wh"},"source":["import pandas as pd \n","train_data=pd.read_csv('gdrive/My Drive/Colab Notebooks/ulm_train.csv')\n","stopwords=pd.read_csv('gdrive/My Drive/Colab Notebooks/Stopwords.csv')\n","test_data=pd.read_csv('gdrive/My Drive/Colab Notebooks/ulm_test.csv')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pdk_7BTox-21","executionInfo":{"status":"ok","timestamp":1603063758265,"user_tz":-360,"elapsed":1680,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"80f25902-3719-47b4-b33c-8d80cf384663","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["!git clone -l -s https://github.com/banglakit/bengali-stemmer.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'bengali-stemmer'...\n","warning: --local is ignored\n","remote: Enumerating objects: 25, done.\u001b[K\n","remote: Counting objects: 100% (25/25), done.\u001b[K\n","remote: Compressing objects: 100% (17/17), done.\u001b[K\n","remote: Total 94 (delta 5), reused 16 (delta 4), pack-reused 69\u001b[K\n","Unpacking objects: 100% (94/94), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M4e-gGoXx-0Y","executionInfo":{"status":"ok","timestamp":1603063764072,"user_tz":-360,"elapsed":4476,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"53284df2-3ae0-4cf6-cff2-b023a09cabee","colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["!pip install git+https://github.com/banglakit/bengali-stemmer.git    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/banglakit/bengali-stemmer.git\n","  Cloning https://github.com/banglakit/bengali-stemmer.git to /tmp/pip-req-build-i783t4he\n","  Running command git clone -q https://github.com/banglakit/bengali-stemmer.git /tmp/pip-req-build-i783t4he\n","Building wheels for collected packages: bengali-stemmer\n","  Building wheel for bengali-stemmer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bengali-stemmer: filename=bengali_stemmer-0.0.1-py2.py3-none-any.whl size=6393 sha256=ad6d76fcff2f60b9a078c92b5b3c949800e274f9da8e2ebb167f704b7a1a9e52\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-d22s3528/wheels/a1/ad/a1/4ba354059b17c00600a14e13a504e7bdb49f20f2f4e2f3639c\n","Successfully built bengali-stemmer\n","Installing collected packages: bengali-stemmer\n","Successfully installed bengali-stemmer-0.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hyi0qd0sytO0","executionInfo":{"status":"ok","timestamp":1603063765966,"user_tz":-360,"elapsed":882,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"515e0d77-9c32-4fdb-909a-96add96929af","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from bengali_stemmer.rafikamal2014 import RafiStemmer\n","stemmer = RafiStemmer()\n","stemmer.stem_word('বাংলায়')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'বাংলা'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"hZo0xYBryuCz"},"source":["total_data = train_data\n","total_data=total_data.append(test_data, ignore_index = True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8JOLtx0ayuG5"},"source":["macronum=sorted(set(total_data['label']))\n","macro_to_id = dict((note, number) for number, note in enumerate(macronum))\n","\n","def fun(i):\n","    return macro_to_id[i]\n","\n","total_data['label']=total_data['label'].apply(fun)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tewahXg0yuKu"},"source":["texts = list(total_data['text'])\n","labels = list(total_data['label'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EMSpULmSDCMF"},"source":["texts.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jyzRbPcWyuOg"},"source":["def clean_punct(sentence):\n","    cleaned = re.sub(r'[?|!|\\'|\"|#|।|’|‘]', r'', sentence)\n","    cleaned1 = re.sub(r'[.|,|(|)|\\|/]', r'', cleaned)\n","    cleaned = re.sub(r'[০|১|২|৩|৪|৫|৬|৭|৮|৯]', r'', cleaned1)\n","    cleaned1 = re.sub(r'[-|=]', r' ', cleaned)\n","    return cleaned1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUr_SPrEyuI5"},"source":["set_stop = set(stopwords['words'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"swZ8QsjMzEpf"},"source":["\n","def pre_process(data):\n","    i=0\n","    str1=' '\n","    final_string = []\n","    final_words = []\n","    all_negative_words = []\n","    s=''\n","\n","    for sentence in data:\n","        filtered_sentence = []\n","\n","        for w in sentence.split():\n","            for cleaned_word in clean_punct(w).split():\n","                if len(cleaned_word)>2:\n","                    if((cleaned_word) not in set_stop):\n","                        s = stemmer.stem_word(cleaned_word)\n","                        if len(s)>2:\n","                            final_words.append(s)\n","                            filtered_sentence.append(s)\n","                    else:\n","                        continue\n","                else:\n","                    continue\n","\n","        str1 = \" \".join(filtered_sentence)\n","        final_string.append(str1)\n","    return final_string"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OrEw2dJ4zFMh"},"source":["texts = pre_process(texts)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TV9pxB_zFQo","executionInfo":{"status":"ok","timestamp":1603063848757,"user_tz":-360,"elapsed":2271,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"a288c7a6-8e1a-4826-d961-fe3415eca4a7","colab":{"base_uri":"https://localhost:8080/","height":120}},"source":["texts[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'সাম্প্রদায়িক সংঘাত মানবিক প্রতিরোধ সাম্প্রদায়িক সংঘাত মানবিক প্রতিরোধফকির ইলিয়াস দেশ থাকি বহুজাতিক বহুভাষিক মানুষ বাস ধর্মাবলম্বী মতাবলম্বী মানুষ কারো কারো মিল চাইল সামান্য বিষ প্রতিদিন দাঙ্গা তেমন হ্যাঁ প্রি পাঠক মার্কিন যুক্তরাষ্ট্র কথা বলছিএ দেশ মানুষ মানুষ বুক পাঁজর চিবি দেশ কঠোর আইন থাক পার পারব পারব কঠিন শাস্তির মুখোমুখি জীবনবাজি রায়ট কেপাক ভারত উপমহাদেশ জন্ম বিভক্ত রায়ট মধ্য কারোর অজানা জন্মইতিহাস জন্ম পাকিস্তান ভারত পরবর্তীকাল বাংলাদেশ ভূখণ্ড দ্বিজাতি তত্ত্ব শত্রু সম্পত্তি আইন মানুষ মানুষ ধর্ম বিভাজন সেভাব পরিকল্পিতভাব সাল ভারত ভাগ অসংখ্য হিন্দু ঘরবাড়ি ছেড় গিয় জিন্নাহর দ্বিজাতি তত্ত্ব ভিত্তি ওঠা দেশ অস্তিত্ব রক্ষা প্রশ্ন প্রথম সাল পূর্বতন পূর্ব পাকিস্তান সাম্প্রদায়িক দাঙ্গ হিন্দু নিরাপত্ত পালি সাল হিন্দু আওয়ামী লীগ ভোট বিশ্বাস দখলদ পাক সেনা সহযোগী প্রবল প্রতিশোধস্পৃহা খুঁজ খুঁজ হিন্দু নিধন চালি হিন্দু বুদ্ধিজীবী সমাজসেবী শ্রদ্ধে ব্যক্তিত্ব ঢাকা বিশ্ববিদ্যালয় জগন্নাথ সহস্রাধিক হিন্দু ছাত্র হত্যা সাল নভেম্বর তারিখ ইউএস সিনেট কমি প্রামাণ্য প্রতিবেদন সিনেটর এডওয়ার্ড কেনেডি লিখ “সব আঘাত হিন্দু সম্প্রদায় মানুষ জমি কেড় দোকান লুট পরিকল্পিতভাব হত্যা জায়গা শরীর হলুদ এইচ লিখ ইসলামাবা সামরিক শাসক আদেশ অনুমতিক্রমে”এরপর বাংলাদেশ চিত্র সাল রাষ্ট্র জনক শেখ মুজিবুর রহমান হত্য দেশ হিন্দু সম্প্রদা আক্রমণ লক্ষ্য হিসেব ধর্ষণসহ পাশবিক অত্যাচ হিন্দু পরিবারগু বাংলাদেশ ছাড় বাধ্য উদাহরণ আছেএকইভাব সাল এরশা সামরিক সরকার পতন হিন্দু আক্রমণ চালি জামায়াত কর্মী দেশ ছাড় ধর্মান্তরিত বাধ্য আগুন লাগি ভাঙচুর চালি ধ্বংস বাড়িঘর ব্যবস জায়গা উপাসনাস্থল হিন্দু জমি অন্যান্য সম্পত্তি লুট হয়েছিলএ ধারাবাহিকতা উদাহরণ সাল নির্বাচনোত্তর হিন্দু বিরোধী হিংসাত্মক কাণ্ডকারখান তদন্ নেম বিচারপতি সাহাবুদ্দিন নেতৃত্বাধীন বিচ বিভাগী কমিশন ধরন অত্যাচ বন্ধ সুপারিশ সুপারিশ দুষ্কৃতকারী সাল অক্টোবর সাল ডিসেম্বর হত্যা নির্দিষ্ট অপরাধ দেশ জেলা তদন্ত কমি কমিশন গঠন কথা জেলাগু তদন্তকারী কমিটিগুলির কাজকর্ম নজরদারি স্বরাষ্ট্র মন্ত্রক অধীন আলাদা খোলা হিংস শিক আইনি সহায়তা কথা সুপারিশগু মানা ধরন হিংসাত্মক ঘটনা জড়িত নাম কমিশন অপরাধী চিহ্নিত করল রহস্যজনকভাব পদক্ষেপ সরকার পক্ষ থেকেঅথচ দেশ মহান মুক্তিযুদ্ধ সকল সম্প্রদায় মানুষ রক্তগঙ্গা বাংলাদেশ ধারাবাহিকতা আক্রমণ নাসিরনগর হবিগঞ্জ ছাতক স্থান হিন্দু ধর্মাবলম্বী আক্রমণ ঘরবাড়ি পুড়ি হয়েছেফেসবু ইসলাম অবমানন অভিযোগ অক্টোবর নাসিরনগর মন্দির হিন্দু সম্প্রদায় দেড় শতাধিক ভাঙচুর লুটপাট চালানো ঘটনা স্থানী প্রশাসন গাফিলতি অভিযোগ নাসিরনগর ইউএন মোয়াজ্জেম ওসি আবদুল কাদের উপস্থিতি সমাবেশ উসকানিমূলক বক্তব্য হামলা হয়নাসিরনগর দত্তবাড়ির বাসিন্দা নীলিমা দত্ত বিবিসি মুসলমান হামলা আরেক মুসলমান বাঁচাই রক্ষা লুটপাট বলছি ধরন সাম্প্রদায়িক আক্রমণ জীবন কখনো দেখেননি হামলাকারী পূজামণ্ডপ ভাঙচুর করল মুসলমান যুবক বাধ কারণ বাসস্থান ঢুক পারেনি বাইর ঢিল ছুঁড় এমনকি সাল বাংলাদেশ মুক্তিযুদ্ধ দত্তবাড়ি ধরন আক্রমণ নীলিমা দত্ত উল্লেখ বাংলাদেশ মুক্তিযুদ্ধ মুসলমান সহযোগিতা হিন্দু দত্তবাড়ি পূজ আয়োজন এখানক বাসিন্দা জানিয়েছেননীলিমা দত্ত হিন্দু যুবক ফেসবুক অ্যাকাউন্ট কাবাঘর অবমাননা কঠোর শাস্তি দরক নেপথ্য দরক ছবির হিন্দুবাড়ি মন্দির হামলা চালানো প্রশ্ন উত্তর খুঁজ পাচ্ছ নীলিমা দত্তবাংলাদেশ নেপথ্য মতলব খুঁজ দরক সরক বেকায়দা চাই সরকার সকল ভালো কাজ তালিকাএখন মানবিক বিবেক জাগ্রত প্রত্য কথা দেশ বিশিষ্টজন সংখ্যালঘু রক্ষা বাংলাদেশ পবিত্র সাংবিধানিক দায়িত্ব মন্তব্য সেক্টরস কমান্ডারস ফোরাম নেতা ফোরাম নেতা ধর্ম যুদ্ধ করিনি অসাম্প্রদায়িক রাষ্ট্র যুদ্ধ করে যুদ্ধাপরাধী বাঁচা হামলা ইন্ধন রামু উখিয়া ঘটনা সহিংসতা সুপরিকল্পিত দেশ স্থিতিশীলতা বিনষ্ট চক্র ঘটনা সংবাদ সম্মেলন সংগঠন চেয়ারম্যান মেজর জেনার কেএম শফিউল্লাহ মহাসচিব হারুন হাবীব সাংস্কৃতিক ব্যক্তিত্ব হামিদ রাখেনএক কথা দেশ তথ্যমন্ত্রী তথ্যমন্ত্রী জাসদ সভাপতি হাসানুল ইনু বাংলাদেশ শান্তি বিনষ্ট চক্রান্ত এখনো অব্যাহত ব্রাক্ষণবাড়িয়া সংখ্যালঘু ওপর হামলা মন্দির ভাঙচুর বাংলাদেশ শান্তি বিনষ্ট চক্রান্ত অংশ শেখ হাসিন নেতৃত্ব সরক সাম্প্রদায়িক সম্প্রীতি বিশ্বাসী যুদ্ধাপরাধী জঙ্গি সন্ত্রাসী রেহা পায়নি তেমনি বাংলাদেশ সংখ্যালঘু ওপর আক্রমণকারী রেহা পাব নাইনু যেহেতু বাংলাদেশ সংবিধান গণতান্ত্রিক প্রক্রিয় বিরুদ্ধ চক্রান্ত অব্যাহত সেহেতু বিএনপি জামায়াত ওপর সর্তক দৃষ্ প্রশাসন সংখ্যালঘু সম্প্রদায় ওপর আক্রমণকারী বিরুদ্ধ কঠোর অবস্থা গ্রহণ সরকার সিদ্ধান্ত বাইর বিচ্ছিন্ন মন্তব্যকারী সরকার সম্পর্ক নেইআম কথা প্রা শুনি দেশ আপনা দিলো কথা দেশ কথাকথা মেন নিলাম আচ্ছা দেশ সামান্য লুট সেজ মুনাফাখোর চোরাকারবারি প্রতারক দখলদ রাজনীতিবিদ পালিত দালাল ক্ষমতাবান বাণী শোনা নাআর দেশ দেশ বাংলাদেশ সংখ্যালঘু ঐক্য মশক কোথা দখলদ ঐক্য করবেমানুষ এগো ধর্ম দোহা রাজনীতি প্রজন্ম দূর থাক ভোট ধর্ম ধর্ম পবিত্র আমানত রাজনীতি রাষ্ট্র পরিচালন দালিলিক বিষ ধর্ম দোহা কখনো রাজনীতি রাজনীতির ধর্ম টেন ধর্ম অপমান ধর্ম ধর্ম জায়গা রাজনীতি রাজনীতির জায়গা উচিতসকল অপশক্তি রোখ প্রধান হাতিয় মানুষ ঐক্য ধর্ম বর্ণ গোত্র নির্বিশেষ দেশ এগি বাংলাদেশ কালোশক্তি সবসম সোচ্চ বিষদাঁত ভেঙ এলাকা এলাকা প্রতিরোধ তুল ন্যায্যতা সত্য পক্ষেএ তরুণ ভূমিকা প্রখর সাহসী দৈনিক খোলাকাগজ ঢাকা নভেম্বর শুক্রব সর্বশেষ এডিট নভেম্বর সকাল'"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"hWnkpDvMzFLb"},"source":["def load_data(num_words, sequence_length, test_size=0.25, oov_token=None):\n","    tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n","    num_classes=6\n","    y = to_categorical(np.asarray(labels), num_classes)\n","    tokenizer.fit_on_texts(texts)\n","    X = tokenizer.texts_to_sequences(texts)\n","    X = np.array(X)\n","    # pad sequences with 0's\n","    X = pad_sequences(X, maxlen=sequence_length)\n","    # split data to training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=1)\n","    data = {}\n","    data[\"X_train\"] = X_train\n","    data[\"X_test\"]= X_test\n","    data[\"y_train\"] = y_train\n","    data[\"y_test\"] = y_test\n","    data[\"tokenizer\"] = tokenizer\n","    return data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6SC9C0Dx-ur"},"source":["# train_data=pd.read_csv('gdrive/My Drive/Colab Notebooks/ulm_train.csv')\n","\n","def get_embedding_vectors(word_index, embedding_size=100):\n","    \n","    embedding_matrix = np.zeros((len(word_index) + 1, embedding_size))\n","    with open(f\"gdrive/My Drive/Colab Notebooks/bn_glove.{embedding_size}d.txt\", encoding=\"utf8\") as f:\n","        for line in tqdm(f, \"Reading GloVe\"):\n","            values = line.split()\n","            # get the word as the first word in the line\n","            word = values[0]\n","            if word in word_index:\n","                idx = word_index[word]\n","                # get the vectors as the remaining values in the line\n","                embedding_matrix[idx] = np.array(values[1:], dtype=\"float32\")\n","    return embedding_matrix"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Qzb-Pynzufb"},"source":["MAX_SEQUENCE_LENGTH = 11276    #max([len(s.split()) for s in texts]) \n","MAX_NUM_WORDS = 109804   # 109803 +1\n","vocab_size = MAX_NUM_WORDS\n","EMBEDDING_DIM = 300\n","VALIDATION_SPLIT = 0.2\n","\n","data = load_data(MAX_NUM_WORDS , MAX_SEQUENCE_LENGTH,VALIDATION_SPLIT)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tdfGyAyPz1HY","executionInfo":{"status":"ok","timestamp":1603063864832,"user_tz":-360,"elapsed":3171,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"65b60049-4693-4fea-9795-d77ce320b96a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(data['tokenizer'].word_index)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["109803"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"m0QOL41Kz41Z","executionInfo":{"status":"ok","timestamp":1603063875740,"user_tz":-360,"elapsed":8447,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"80a87523-00cd-4c1f-e306-623b86484474","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["embedding_matrix = get_embedding_vectors( data['tokenizer'].word_index ,EMBEDDING_DIM )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading GloVe: 134256it [00:07, 18859.40it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"40PiUDGVz8Bp"},"source":["embedding_layer = Embedding(len(data['tokenizer'].word_index) + 1,  # or we can use 'MAX_NUM_WORDS'\n","                            EMBEDDING_DIM,\n","                            weights=[embedding_matrix],\n","                            input_length=MAX_SEQUENCE_LENGTH,\n","                            trainable=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CfxmcqbN0luU"},"source":["\n","'''\n","print('Training model.')\n","\n","# train a 1D convnet with global maxpooling\n","sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n","embedded_sequences = embedding_layer(sequence_input)\n","x = Conv1D(128, 5, activation='relu')(embedded_sequences)\n","x = MaxPooling1D(5)(x)\n","x = Conv1D(128, 5, activation='relu')(x)\n","x = MaxPooling1D(5)(x)\n","x = Conv1D(128, 5, activation='relu')(x)\n","x = MaxPooling1D(35)(x)  # global max pooling\n","x = Flatten()(x)\n","x = Dense(128, activation='relu')(x)\n","preds = Dense(6, activation='softmax')(x)\n","\n","model = Model(sequence_input, preds)\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',   # using 'rmsprop' optimizer\n","              metrics=['acc'])\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTiROvnm024A"},"source":["#model.fit(data['X_train'], data['y_train'], validation_data=(data['X_test'], data['y_test']),epochs=5, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQL9-uybB42E","executionInfo":{"status":"ok","timestamp":1603063887015,"user_tz":-360,"elapsed":3441,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"a69d3abc-0148-4739-e02e-600cd22700d7","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["pip install keras-self-attention\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: keras-self-attention in /usr/local/lib/python3.6/dist-packages (0.47.0)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.5)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-self-attention) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UrbUroWpDyBi","executionInfo":{"status":"ok","timestamp":1603063987832,"user_tz":-360,"elapsed":3556,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"021b3990-7490-44f8-b58d-20ca9363eb74","colab":{"base_uri":"https://localhost:8080/","height":768}},"source":["pip install attention\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting attention\n","  Downloading https://files.pythonhosted.org/packages/2d/27/98d7350db36a3537e24c9ec488d893b71092037f5c74e8984d01e9c1d316/attention-3.0-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.6/dist-packages (from attention) (1.18.5)\n","Requirement already satisfied: keras>=2.3.1 in /usr/local/lib/python3.6/dist-packages (from attention) (2.4.3)\n","Requirement already satisfied: tensorflow>=2.1 in /usr/local/lib/python3.6/dist-packages (from attention) (2.3.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.3.1->attention) (2.10.0)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.3.1->attention) (1.4.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.3.1->attention) (3.13)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (1.6.3)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (1.32.0)\n","Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (1.1.2)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (0.35.1)\n","Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (2.3.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (1.15.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (0.10.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (3.12.4)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (0.3.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n","Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (2.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.1->attention) (1.12.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow>=2.1->attention) (50.3.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (3.2.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (2.23.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (1.17.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (0.4.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (1.7.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (2.0.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (1.24.3)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (1.3.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (3.2.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow>=2.1->attention) (3.1.0)\n","Installing collected packages: attention\n","Successfully installed attention-3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UHfLVqeY1Gud","executionInfo":{"status":"error","timestamp":1603064323834,"user_tz":-360,"elapsed":1129,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"0901d98c-4c47-48ca-d87d-1049b3c3f17f","colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["from keras_self_attention import SeqSelfAttention\n","from attention import Attention\n","\n","\n","# define model\n","model = Sequential()\n","model.add(embedding_layer)\n","#model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n","#model.add(MaxPooling1D(pool_size=2))\n","model.add(LSTM(128))\n","model.add(Attention(name='attention_weight'))\n","\n","model.add(Flatten())\n","model.add(Dense(6, activation='softmax'))\n","print(model.summary())\n","\n","\n","'''\n","import keras\n","from keras_self_attention import SeqSelfAttention\n","\n","inputs = keras.layers.Input(shape=(None,))\n","embd = keras.layers.Embedding(input_dim=32,\n","                              output_dim=16,\n","                              mask_zero=True)(inputs)\n","lstm = keras.layers.Bidirectional(keras.layers.LSTM(units=16,\n","                                                    return_sequences=True))(embd)\n","att = SeqSelfAttention(attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n","                       kernel_regularizer=keras.regularizers.l2(1e-4),\n","                       bias_regularizer=keras.regularizers.l1(1e-4),\n","                       attention_regularizer_weight=1e-4,\n","                       name='Attention')(lstm)\n","dense = keras.layers.Dense(units=5, name='Dense')(att)\n","model = keras.models.Model(inputs=inputs, outputs=[dense])\n","model.compile(\n","    optimizer='adam',\n","    loss={'Dense': 'sparse_categorical_crossentropy'},\n","    metrics={'Dense': 'categorical_accuracy'},\n",")\n","model.summary(line_length=100)\n","\n","\n","\n","m = Sequential([\n","      LSTM(128, input_shape=(seq_length, 1), return_sequences=True),\n","      Attention(name='attention_weight'), # <--------- here.\n","      Dense(1, activation='linear')\n","])\n","\n","model = Sequential()\n","model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n","model.add(SpatialDropout1D(0.2))\n","model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(13, activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","epochs = 5\n","batch_size = 64\n","\n","'''"],"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-16020b321ae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#model.add(MaxPooling1D(pool_size=2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'attention_weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    219\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/attention/attention.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfelixhao28\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \"\"\"\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Inside dense layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#              hidden_states            dot               W            =>           score_first_part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    885\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","metadata":{"id":"ac3PMBkr1Gpk"},"source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # using adma optimizer\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbaJ7wEC8Pii","executionInfo":{"status":"ok","timestamp":1603062192288,"user_tz":-360,"elapsed":146548,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"ae628ba0-5eec-482a-f81d-26868e15769e","colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["#history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n","\n","history = model.fit(data['X_train'], data['y_train'], validation_data=(data['X_test'], data['y_test']), epochs=5, verbose=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","53/53 - 29s - loss: 1.2180 - accuracy: 0.5554 - val_loss: 1.0330 - val_accuracy: 0.5952\n","Epoch 2/5\n","53/53 - 28s - loss: 0.8436 - accuracy: 0.6804 - val_loss: 0.8458 - val_accuracy: 0.6929\n","Epoch 3/5\n","53/53 - 28s - loss: 0.6159 - accuracy: 0.7869 - val_loss: 0.7848 - val_accuracy: 0.7190\n","Epoch 4/5\n","53/53 - 28s - loss: 0.4891 - accuracy: 0.8381 - val_loss: 0.8269 - val_accuracy: 0.7095\n","Epoch 5/5\n","53/53 - 28s - loss: 0.3549 - accuracy: 0.8917 - val_loss: 0.7996 - val_accuracy: 0.7429\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eQMJnAKd2NZg","executionInfo":{"status":"ok","timestamp":1603061960246,"user_tz":-360,"elapsed":296509,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"8e9bfda0-1fd3-44d6-c2f3-cbb2b07a55a6","colab":{"base_uri":"https://localhost:8080/","height":357}},"source":["#history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n","# don't take count this epoch's\n","history = model.fit(data['X_train'], data['y_train'], validation_data=(data['X_test'], data['y_test']), epochs=10, verbose=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","53/53 - 29s - loss: 1.2479 - accuracy: 0.5220 - val_loss: 1.0181 - val_accuracy: 0.6524\n","Epoch 2/10\n","53/53 - 28s - loss: 0.8068 - accuracy: 0.7065 - val_loss: 0.8180 - val_accuracy: 0.7024\n","Epoch 3/10\n","53/53 - 28s - loss: 0.5850 - accuracy: 0.7994 - val_loss: 0.7837 - val_accuracy: 0.7429\n","Epoch 4/10\n","53/53 - 28s - loss: 0.4276 - accuracy: 0.8619 - val_loss: 0.8517 - val_accuracy: 0.6976\n","Epoch 5/10\n","53/53 - 28s - loss: 0.2891 - accuracy: 0.9173 - val_loss: 0.7804 - val_accuracy: 0.7452\n","Epoch 6/10\n","53/53 - 28s - loss: 0.1720 - accuracy: 0.9589 - val_loss: 0.7999 - val_accuracy: 0.7595\n","Epoch 7/10\n","53/53 - 28s - loss: 0.0926 - accuracy: 0.9810 - val_loss: 0.7680 - val_accuracy: 0.7762\n","Epoch 8/10\n","53/53 - 28s - loss: 0.0907 - accuracy: 0.9839 - val_loss: 0.8334 - val_accuracy: 0.7762\n","Epoch 9/10\n","53/53 - 28s - loss: 0.0473 - accuracy: 0.9940 - val_loss: 0.8169 - val_accuracy: 0.7643\n","Epoch 10/10\n","53/53 - 28s - loss: 0.0244 - accuracy: 0.9964 - val_loss: 0.9138 - val_accuracy: 0.7381\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4-IubUZ07N_A"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HSaPMib82Smw"},"source":["import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","import matplotlib.pyplot as plt\n","def confussion_mat(model):\n","    # Predict the values from the validation dataset\n","    Y_pred = model.predict(data['X_test'])\n","    # Convert predictions classes to one hot vectors \n","    Y_pred_classes = np.argmax(Y_pred,axis = 1) \n","    # Convert validation observations to one hot vectors\n","    Y_true = np.argmax(data['y_test'],axis = 1) \n","    # compute the confusion matrix\n","    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n","    # plot the confusion matrix\n","    f,ax = plt.subplots(figsize=(15, 15))\n","    sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n","    plt.xlabel(\"Predicted Label\")\n","    plt.ylabel(\"True Label\")\n","    plt.title(\"Confusion Matrix\")\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C0YGbxQ62SrC"},"source":["def history2(history):\n","    # list all data in history\n","    print(history.history.keys())\n","    # summarize history for accuracy\n","    plt.plot(history.history['accuracy'])\n","    plt.plot(history.history['val_accuracy'])\n","    plt.title('model accuracy')\n","    plt.ylabel('accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()\n","    # summarize history for loss\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('model loss')\n","    plt.ylabel('loss')\n","    plt.xlabel('epoch')\n","    plt.legend(['train', 'test'], loc='upper left')\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nau8_-Nv2SxO"},"source":["history2(history)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AT7bxtQ32Sua"},"source":["confussion_mat(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xN8j8Uhj2Spb"},"source":[""],"execution_count":null,"outputs":[]}]}